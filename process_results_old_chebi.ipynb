{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "This script evaluates two models trained on the datasets $ChEBI_{v200}^{854}$ and $ChEBI_{v148}^{709}$."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-01T09:09:32.987478800Z",
     "start_time": "2023-12-01T09:09:32.979311Z"
    }
   },
   "outputs": [],
   "source": [
    "from chebai.preprocessing.datasets.chebi import ChEBIOver100\n",
    "from chebai.preprocessing.datasets.base import XYBaseDataModule\n",
    "from chebai.models.electra import Electra\n",
    "from chebai.models.base import ChebaiBaseNet\n",
    "\n",
    "from torchmetrics.classification import MultilabelF1Score\n",
    "import numpy as np\n",
    "from chebai.result import pretraining as eval_pre\n",
    "from chebai.preprocessing.datasets.pubchem import PubChemDeepSMILES\n",
    "from chebai.result.base import ResultProcessor\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import chebai.models.electra as electra\n",
    "from chebai.loss.pretraining import ElectraPreLoss\n",
    "import torch\n",
    "import tqdm\n",
    "\n",
    "DEVICE = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-12-01T09:09:34.279433900Z",
     "start_time": "2023-12-01T09:09:34.063840600Z"
    }
   },
   "outputs": [],
   "source": [
    "model_path_v200 = os.path.join(\"models\", \"electra_c100_bce_unweighted.ckpt\")\n",
    "model_path_v148 = os.path.join(\"models\", \"electra_c100_bce_unweighted_v148.ckpt\")\n",
    "\n",
    "model_v200 = Electra.load_from_checkpoint(model_path_v200).to(DEVICE)\n",
    "model_v148 = Electra.load_from_checkpoint(model_path_v148).to(DEVICE)\n",
    "\n",
    "data_module_v200 = ChEBIOver100(chebi_version=200)\n",
    "data_module_v148 = ChEBIOver100(chebi_version=200, chebi_version_train=148)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-12-01T09:09:35.203500700Z",
     "start_time": "2023-12-01T09:09:35.195490300Z"
    }
   },
   "outputs": [],
   "source": [
    "classes_file_v200 = \"classes.txt\"\n",
    "classes_file_v148 = f\"classes_v148.txt\"\n",
    "with open(os.path.join(data_module_v200.raw_dir, classes_file_v200), \"r\") as file:\n",
    "    v200_classes = file.readlines()\n",
    "with open(os.path.join(data_module_v148.raw_dir, classes_file_v148), \"r\") as file:\n",
    "    v148_classes = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-12-01T09:09:37.604040300Z",
     "start_time": "2023-12-01T09:09:37.598008300Z"
    }
   },
   "outputs": [],
   "source": [
    "# get list of classes that appear in v200 and v148\n",
    "common_classes = []\n",
    "for v200_class in v200_classes:\n",
    "    if v200_class in v148_classes:\n",
    "        common_classes.append(v200_class)\n",
    "# get filter if a class in v200/v148 is a common class\n",
    "common_classes_mask_v200 = torch.tensor([[c in common_classes for c in v200_classes]])\n",
    "common_classes_mask_v148 = torch.tensor([[c in common_classes for c in v148_classes]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-12-01T09:11:07.922759200Z",
     "start_time": "2023-12-01T09:11:07.914456300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes in ChEBI_v148: 709\n",
      "Number of classes in ChEBI_v200: 854\n",
      "Number of classes in both versions: 701\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of classes in ChEBI_v148: {len(v148_classes)}\")\n",
    "print(f\"Number of classes in ChEBI_v200: {len(v200_classes)}\")\n",
    "print(f\"Number of classes in both versions: {len(common_classes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(\n",
    "    model: ChebaiBaseNet,\n",
    "    data_module: XYBaseDataModule,\n",
    "    common_classes_mask=None,\n",
    "    test_file=None,\n",
    "):\n",
    "    collate = data_module.reader.COLLATER()\n",
    "    if test_file is None:\n",
    "        test_file = data_module.processed_file_names_dict[\"test\"]\n",
    "    data_path = os.path.join(data_module.processed_dir, test_file)\n",
    "    data_list = torch.load(data_path)\n",
    "    preds_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for row in tqdm.tqdm(data_list):\n",
    "        processable_data = model._process_batch(collate([row]), 0)\n",
    "        model_output = model(processable_data)\n",
    "        preds, labels = model._get_prediction_and_labels(\n",
    "            processable_data, processable_data[\"labels\"], model_output\n",
    "        )\n",
    "        if common_classes_mask is not None:\n",
    "            preds = preds[common_classes_mask]\n",
    "            labels = labels[common_classes_mask]\n",
    "            preds_list.append(preds.unsqueeze(0))\n",
    "            labels_list.append(labels.unsqueeze(0))\n",
    "        else:\n",
    "            preds_list.append(preds)\n",
    "            labels_list.append(labels)\n",
    "\n",
    "    test_preds = torch.cat(preds_list)\n",
    "    test_labels = torch.cat(labels_list)\n",
    "    print(test_preds.shape)\n",
    "    print(test_labels.shape)\n",
    "    f1_macro = MultilabelF1Score(test_preds.shape[1], average=\"macro\")\n",
    "    f1_micro = MultilabelF1Score(test_preds.shape[1], average=\"micro\")\n",
    "    print(\n",
    "        f\"Macro-F1 on test set with {test_preds.shape[1]} classes: {f1_macro(test_preds, test_labels):3f}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Micro-F1 on test set with {test_preds.shape[1]} classes: {f1_micro(test_preds, test_labels):3f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16486/16486 [07:24<00:00, 37.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16486, 854])\n",
      "torch.Size([16486, 854])\n",
      "Macro-F1 on test set with 854 classes: 0.603181\n",
      "Micro-F1 on test set with 854 classes: 0.902437\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model_v200, data_module_v200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16486/16486 [07:21<00:00, 37.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16486, 701])\n",
      "torch.Size([16486, 701])\n",
      "Macro-F1 on test set with 701 classes: 0.623063\n",
      "Micro-F1 on test set with 701 classes: 0.905059\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model_v200, data_module_v200, common_classes_mask_v200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16486/16486 [05:31<00:00, 49.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16486, 709])\n",
      "torch.Size([16486, 709])\n",
      "Macro-F1 on test set with 709 classes: 0.513283\n",
      "Micro-F1 on test set with 709 classes: 0.854591\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model_v148, data_module_v148)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 16486/16486 [05:16<00:00, 52.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16486, 701])\n",
      "torch.Size([16486, 701])\n",
      "Macro-F1 on test set with 701 classes: 0.519968\n",
      "Micro-F1 on test set with 701 classes: 0.855442\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model_v148, data_module_v148, common_classes_mask_v148)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
