{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "726ada05-9a23-46bc-a04a-c951ccd29807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\HP\\Desktop\\github-aditya0by0\\python-chebai\n"
     ]
    }
   ],
   "source": [
    "# ---------------- For testing only : comment afterwards\n",
    "# import os\n",
    "\n",
    "# # Set the root directory\n",
    "# root_directory = r\"C:\\Users\\HP\\Desktop\\github-aditya0by0\\python-chebai\"\n",
    "# os.chdir(root_directory)\n",
    "\n",
    "# # Verify the current working directory\n",
    "# print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T13:47:31.150545Z",
     "start_time": "2024-04-02T13:47:27.181585Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\envs\\env_chebai\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from chebai.result.utils import (\n",
    "    evaluate_model,\n",
    "    load_results_from_buffer,\n",
    ")\n",
    "from chebai.result.classification import print_metrics\n",
    "from chebai.models.electra import Electra\n",
    "from chebai.preprocessing.datasets.chebi import ChEBIOver50, ChEBIOver100\n",
    "import os\n",
    "import tqdm\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdb5fc6919cf72be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T13:47:35.484307Z",
     "start_time": "2024-04-02T13:47:35.477111Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check for processed data in data\\chebi_v231\\ChEBI50\\processed\\smiles_token\n",
      "Cross-validation enabled: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check for processed data in data\\chebi_v231\\ChEBI50\\processed\n",
      "saving 771 tokens to C:\\Users\\HP\\Desktop\\github-aditya0by0\\python-chebai\\chebai\\preprocessing\\bin\\smiles_token\\tokens.txt...\n",
      "first 10 tokens: ['[*-]', '[Al-]', '[F-]', '.', '[H]', '[N]', '(', ')', '[Ag+]', 'C']\n",
      "Get test data split\n",
      "Split dataset into train / val with given test set\n"
     ]
    }
   ],
   "source": [
    "# specify the checkpoint name\n",
    "checkpoint_name = \"my_trained_model\"\n",
    "checkpoint_path = os.path.join(\"logs\", f\"{checkpoint_name}.ckpt\")\n",
    "kind = \"test\"  # replace with \"train\" / \"validation\" to run on train / validation sets\n",
    "buffer_dir = os.path.join(\"results_buffer\", checkpoint_name, kind)\n",
    "# make sure to use the same data module and model class that were used during training\n",
    "data_module = ChEBIOver50(\n",
    "    chebi_version=231,\n",
    ")\n",
    "# load chebi data if missing and perform dynamic splits\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "model_class = Electra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42642a53-511d-4cbc-a799-56641c89aebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Desktop\\github-aditya0by0\\python-chebai\\logs\\chebi50_bce_unweighted\\version_27\\checkpoints\\per_epoch=99_val_loss=0.1377_val_macro-f1=0.0200_val_micro-f1=0.2947.ckpt\n"
     ]
    }
   ],
   "source": [
    "# --------------- For testing only : comment afterwards\n",
    "# data_module.data_limit = 100\n",
    "# main_directory = r\"C:\\Users\\HP\\Desktop\\github-aditya0by0\\python-chebai\"\n",
    "# checkpoint_name = r\"logs\\chebi50_bce_unweighted\\version_27\\checkpoints\\per_epoch=99_val_loss=0.1377_val_macro-f1=0.0200_val_micro-f1=0.2947\"\n",
    "# checkpoint_path = os.path.join(main_directory, f\"{checkpoint_name}.ckpt\")\n",
    "# print(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa1276b47def696c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-02T13:47:38.418564Z",
     "start_time": "2024-04-02T13:47:37.861168Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████| 10/10 [00:06<00:00,  1.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# evaluates model, stores results in buffer_dir\n",
    "model = model_class.load_from_checkpoint(checkpoint_path)\n",
    "if buffer_dir is None:\n",
    "    preds, labels = evaluate_model(\n",
    "        model,\n",
    "        data_module,\n",
    "        buffer_dir=buffer_dir,\n",
    "        # No need to provide this parameter for Chebi dataset, \"kind\" parameter should be provided\n",
    "        # filename=data_module.processed_file_names_dict[kind],\n",
    "        batch_size=10,\n",
    "        kind=kind,\n",
    "    )\n",
    "else:\n",
    "    evaluate_model(\n",
    "        model,\n",
    "        data_module,\n",
    "        buffer_dir=buffer_dir,\n",
    "        # No need to provide this parameter for Chebi dataset, \"kind\" parameter should be provided\n",
    "        # filename=data_module.processed_file_names_dict[kind],\n",
    "        batch_size=10,\n",
    "        kind=kind,\n",
    "    )\n",
    "    # load data from buffer_dir\n",
    "    preds, labels = load_results_from_buffer(buffer_dir, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "201f750c475b4677",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load classes from the classes.txt\n",
    "with open(os.path.join(data_module.processed_dir_main, \"classes.txt\"), \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e567cd2fb1718baf",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro-F1: 0.290936\n",
      "Micro-F1: 0.890380\n",
      "Balanced Accuracy: 0.507610\n",
      "Macro-Precision: 0.021964\n",
      "Micro-Precision: 0.908676\n",
      "Macro-Recall: 0.020987\n",
      "Micro-Recall: 0.872807\n",
      "Top 10 classes (F1-score):\n",
      "1. 23367 - F1: 1.000000\n",
      "2. 33259 - F1: 1.000000\n",
      "3. 36914 - F1: 1.000000\n",
      "4. 24431 - F1: 1.000000\n",
      "5. 33238 - F1: 1.000000\n",
      "6. 36357 - F1: 1.000000\n",
      "7. 37577 - F1: 1.000000\n",
      "8. 24867 - F1: 1.000000\n",
      "9. 33579 - F1: 0.974026\n",
      "10. 24866 - F1: 0.973684\n",
      "Found 63 classes with F1-score == 0 (and non-zero labels): 17792, 22563, 22632, 22712, 24062, 24834, 25108, 25693, 25697, 25698, 25699, 25806, 26151, 26217, 26218, 26421, 26469, 29347, 32988, 33240, 33256, 33296, 33299, 33304, 33597, 33598, 33635, 33655, 33659, 33661, 33670, 33671, 33836, 33976, 35217, 35273, 35479, 35618, 36364, 36562, 36916, 36962, 36963, 37141, 37143, 37622, 37929, 37960, 38101, 38104, 38166, 38835, 39203, 46850, 47704, 47916, 48592, 50047, 50995, 72544, 79389, 83565, 139358\n"
     ]
    }
   ],
   "source": [
    "# output relevant metrics\n",
    "print_metrics(\n",
    "    preds,\n",
    "    labels.to(torch.int),\n",
    "    DEVICE,\n",
    "    classes=classes,\n",
    "    markdown_output=False,\n",
    "    top_k=10,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
