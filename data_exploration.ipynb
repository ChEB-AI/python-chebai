{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81559360-c8b8-462d-bfa1-6ae22bed1615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd757ea-a6a0-43f8-8701-cafb44f20f6b",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook serves as a guide for new users of the `chebai` package, which is used for working with chemical data, especially focusing on ChEBI (Chemical Entities of Biological Interest). This notebook will explain how to instantiate the main data class, how the data files are structured, and how to work with different molecule encodings.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33275d3c-cdbf-4c1f-aa04-f135511f3643",
   "metadata": {},
   "source": [
    "# 1. Instantiation of a Data Class\r\n",
    "\r\n",
    "To start working with `chebai`, you first need to instantiate a ChEBI data class. This class is responsible for managing, interacting with, and preprocessing the ChEBI chemical data\n",
    "### Inheritance Hierarchy\n",
    "\n",
    "ChEBI data classes inherit from `_DynamicDataset`, which in turn inherits from `XYBaseDataModule`. Specifically:\n",
    "\n",
    "- **`_DynamicDataset`**: This class serves as an intermediate base class that provides additional functionality or customization for datasets that require dynamic behavior. It inherits from `XYBaseDataModule`, which provides the core methods for data loading and processing.\n",
    "\n",
    "- **`XYBaseDataModule`**: This is the base class for data modules, providing foundational properties and methods for handling and processing datasets, including data splitting, loading, and preprocessing.\n",
    "\n",
    "In summary, ChEBI data classes are designed to manage and preprocess chemical data effectively by leveraging the capabilities provided by `XYBaseDataModule` through the `_DynamicDataset` intermediary.\n",
    ".\r\n",
    "\r\n",
    "### Explanation\r\n",
    "a ChEBI data classiData` class can be configured with the following main parameters:\r\n",
    "\r\n",
    "- **chebi_version (int)**: Specifies the version of the ChEBI database to be used. The default is `200`. Specifying a version ensures the reproducibility of your experiments by using a consistent dataset.\r\n",
    "\r\n",
    "- **chebi_version_train (int, optional)**: The version of ChEBI to use specifically for training and validation. If not set, the `chebi_version` specified will be used for all data splits, including training, validation, and test. Defaults to `None`.\r\n",
    "\r\n",
    "- **single_class (int, optional)**: The ID of the single class to predict. If not set, predictions will be made for all available labels. Defaults to `None`.\r\n",
    "\r\n",
    "- **dynamic_data_split_seed (int, optional)**: The seed for random data splitting, which ensures reproducibility. Defaults to `42`.\r\n",
    "\r\n",
    "- **splits_file_path (str, optional)**: Path to a CSV file containing data splits. If not provided, the class will handle splits internally. Defaults to `None`.\r\n",
    "\r\n",
    "- **kwargs**: Additional keyword arguments passed to `XYBaseDataModule`.\r\n",
    "\r\n",
    "These parameters provide flexibility in handling and processing the data, allowing you to set specific versions for different stages of analysis and manage how data is split for training and validation.\r\n",
    "\r\n",
    "### Additional Input Parameters\r\n",
    "\r\n",
    "The `XYBaseDa ChEBI data class, whsich `ChebaiData` may use internally, includes several important parameters for data loading and processing:\r\n",
    "\r\n",
    "- **batch_size (int)**: The batch size for data loading. Default is `1`.\r\n",
    "\r\n",
    "- **train_split (float)**: The ratio of training data to total data and the ratio of test data to (validation + test) data. Default is `0.85`.\r\n",
    "\r\n",
    "- **reader_kwargs (dict)**: Additional keyword arguments to be passed to the data reader. Default is `None`.\r\n",
    "\r\n",
    "- **prediction_kind (str)**: Specifies the kind of prediction to be performed, relevant only for the `predict_dataloader`. Default is `\"test\"`.\r\n",
    "\r\n",
    "- **data_limit (Optional[int])**: The maximum number of data samples to load. If set to `None`, the complete dataset will be used. Default is `None`.\r\n",
    "\r\n",
    "- **label_filter (Optional[int])**: The index of the label to filter. Default is `None`.\r\n",
    "\r\n",
    "- **balance_after_filter (Optional[float])**: The ratio of negative samples to positive samples after filtering. Default is `None`.\r\n",
    "\r\n",
    "- **num_workers (int)**: The number of worker processes for data loading. Default is `1`.\r\n",
    "\r\n",
    "- **inner_k_folds (int)**: The number of folds for inner cross-validation. Use `-1` to disable inner cross-validation. Default is `-1`.\r\n",
    "\r\n",
    "- **fold_index (Optional[int])**: The index of the fold to use for training and validation. Default is `None`.\r\n",
    "\r\n",
    "- **base_dir (Optional[str])**: The base directory for storing processed and raw data. Default is `None`.\r\n",
    "\r\n",
    "- **kwargs**: Additional keyword arguments.\r\n",
    "\r\n",
    "These parameters allow you to control various aspects of data loading, processing, and splitting, providing flexibility in how datasets are managed throughout your analysis pipeline.\r\n",
    "ining and validation.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8578b7aa-1bd9-4e50-9eee-01bfc6d5464a",
   "metadata": {},
   "source": [
    "# Available ChEBI Data Classes\n",
    "\n",
    "## `ChEBIOver100`\n",
    "A class for extracting data from the ChEBI dataset with a threshold of 100 for selecting classes.\n",
    "\n",
    "- **Inheritance**: Inherits from `ChEBIOverX`.\n",
    "\n",
    "## `ChEBIOver50`\n",
    "A class for extracting data from the ChEBI dataset with a threshold of 50 for selecting classes.\n",
    "\n",
    "- **Inheritance**: Inherits from `ChEBIOverX`.\n",
    "\n",
    "## `ChEBIOver100DeepSMILES`\n",
    "A class for extracting data from the ChEBI dataset using the DeepChem SMILES reader with a threshold of 100.\n",
    "\n",
    "- **Inheritance**: Inherits from `ChEBIOverXDeepSMILES` and `ChEBIOver100`.\n",
    "\n",
    "## `ChEBIOver100SELFIES`\n",
    "A class for extracting data from the ChEBI dataset using the SELFIES reader with a threshold of 100.\n",
    "\n",
    "- **Inheritance**: Inherits from `ChEBIOverXSELFIES` and `ChEBIOver100`.\n",
    "\n",
    "## `ChEBIOver50SELFIES`\n",
    "A class for extracting data from the ChEBI dataset using the SELFIES reader with a threshold of 50.\n",
    "\n",
    "- **Inheritance**: Inherits from `ChEBIOverXSELFIES` and `ChEBIOver50`.\n",
    "\n",
    "## `ChEBIOver50Partial`\n",
    "A dataset class that extracts a part of ChEBI based on subclasses of a given top class, with a threshold of 50 for selecting classes.\n",
    "\n",
    "- **Inheritance**: Inherits from `ChEBIOverXPartial` and `ChEBIOver50`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3a66e07-edc9-4aa2-9cd0-d4ea58914d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chebai.preprocessing.datasets.chebi import ChEBIOver50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a71b7301-6195-4155-a439-f5eb3183d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "chebi_class = ChEBIOver50(chebi_version=231)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8456b545-88c5-401d-baa5-47e8ae710f04",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1655d489-25fe-46de-9feb-eeca5d36936f",
   "metadata": {},
   "source": [
    "# 2. Preparation / Setup Methods\r\n",
    "\r\n",
    "Once a ChEBI data class instance is created, it typically requires preparation before use. This step is necessary to download or load the relevant data files and set up the internal data structures.\r\n",
    "\r\n",
    "### Why is Preparation Needed?\r\n",
    "\r\n",
    "- **Data Availability**: The preparation step ensures that the required ChEBI data files are downloaded or loaded, which are essential for analysis.\r\n",
    "- **Data Integrity**: It ensures that the data files are up-to-date and compatible with the specified ChEBI version.\r\n",
    "\r\n",
    "### Main Methods for Data Preprocessing\r\n",
    "\r\n",
    "The data preprocessing in a data class involves two main methods:\r\n",
    "\r\n",
    "1. **`prepare_data` Method**:\r\n",
    "   - **Purpose**: This method checks for the presence of raw data in the specified directory. If the raw data is missing, it fetches the ontology, creates a dataframe, and saves it to a file (`data.pkl`). The dataframe includes columns such as IDs, data representations, and labels.\r\n",
    "   - **Documentation**: [PyTorch Lightning - `prepare_data`](https://lightning.ai/docs/pytorch/stable/data/datamodule.html#prepare-data)\r\n",
    "\r\n",
    "2. **`setup` Method**:\r\n",
    "   - **Purpose**: This method sets up the data module for training, validation, and testing. It checks for the processed data and, if necessary, performs additional setup to ensure the data is ready for model input. It also handles cross-validation settings if enabled.\r\n",
    "   - **Description**: Transforms `data.pkl` into a model input data format (`data.pt`), ensuring that the data is in a format compatible for input to the model. The transformed data contains the following keys: `ident`, `features`, `labels`, and `group`. This method uses a subclass of Data Reader to perform the transformation.\r\n",
    "   - **Documentation**: [PyTorch Lightning - `setup`](https://lightning.ai/docs/pytorch/stable/data/datamodule.html#setup)\r\n",
    "\r\n",
    "These methods ensure that the data is correctly prepared and set up for subsequent use in training and validation processes.\r\n",
    "alidation processes.\r\n",
    "processed(data_df, processed_name)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f2df4bd1-cf34-4414-bce4-54379ffac006",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Check for processed data in data\\chebi_v231\\ChEBI50\\processed\\smiles_token\n",
      "Cross-validation enabled: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check for processed data in data\\chebi_v231\\ChEBI50\\processed\n",
      "saving 771 tokens to G:\\github-aditya0by0\\python-chebai\\chebai\\preprocessing\\bin\\smiles_token\\tokens.txt...\n",
      "first 10 tokens: ['[*-]', '[Al-]', '[F-]', '.', '[H]', '[N]', '(', ')', '[Ag+]', 'C']\n"
     ]
    }
   ],
   "source": [
    "chebi_class.prepare_data()\n",
    "chebi_class.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5aaa12d-5f01-4b74-8b59-72562af953bf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ababadb-003a-4c86-b92d-10e7bd1fba5e",
   "metadata": {},
   "source": [
    "# 3. Different Data Files Created and their Structure\n",
    "\r\n",
    "\r\n",
    "`chebai` creates and manages several data files during its operation. These files store various chemical data and metadata essential for different tasks. Let’s explore these files and their structures.\r\n",
    "\r\n",
    "### Data Files\r\n",
    "\r\n",
    "1. **`Raw Data Files`**: (e.g., `.obo` file)\r\n",
    "   - **Description**: Contains the raw ChEBI ontology data, downloaded directly from the ChEBI website. This file serves as the foundation for data processing.\r\n",
    "   - **File Path**: `data/${chebi_version}/${dataset_name}/raw/${filename}.obo`\r\n",
    "\r\n",
    "2. **`data.pkl`**\r\n",
    "   - **Description**: Generated by the `prepare_data` method, this file contains processed data in a dataframe format. It includes chemical IDs, data representations (such as SMILES strings), and class columns with boolean values.\r\n",
    "   - **File Path**: `data/${chebi_version}/${dataset_name}/processed/data.pkl`\r\n",
    "\r\n",
    "3. **`data.pt`**\r\n",
    "   - **Description**: Generated by the `setup` method, this file contains encoded data in a format compatible with the PyTorch library. It includes keys such as `ident`, `features`, `labels`, and `group`, ready for model input.\r\n",
    "   - **File Path**: `data/${chebi_version}/${dataset_name}/processed/${reader_name}/data.pt`\r\n",
    "\r\n",
    "4. **`classes.txt`**\r\n",
    "   - **Description**: A file containing the list of selected ChEBI classes based on the specified threshold. This file is crucial for ensuring that only relevant classes are included in the dataset.\r\n",
    "   - **File Path**: `data/${chebi_version}/${dataset_name}/processed/classes.txt`\r\n",
    "\r\n",
    "5. **`splits.csv`**\r\n",
    "   - **Description**: Contains saved data splits from previous runs. During subsequent runs, this file is used to reconstruct the train, validation, and test splits by filtering the encoded data (`data.pt`) based on the IDs stored in `splits.csv`.\r\n",
    "   - **File Path**: `data/${chebi_version}/${dataset_name}/processed/splits.csv`\r\n",
    "\r\n",
    "### File Structure and Preprocessing Stages\r\n",
    "\r\n",
    "The `chebai` library follows a three-stage preprocessing pipeline, which is reflected in its file structure:\r\n",
    "\r\n",
    "1. **Raw Data Stage**:\r\n",
    "   - **File**: `chebi.obo`\r\n",
    "   - **Description**: This stage contains the raw ChEBI ontology data, serving as the initial input for further processing.\r\n",
    "   - **File Path**: `data/${chebi_version}/${dataset_name}/raw/${filename}.obo`\r\n",
    "\r\n",
    "2. **Processed Data Stage 1**:\r\n",
    "   - **File**: `data.pkl`\r\n",
    "   - **Description**: This stage includes the data after initial processing. It contains SMILES strings, class columns, and metadata but lacks data splits.\r\n",
    "   - **File Path**: `data/${chebi_version}/${dataset_name}/processed/data.pkl`\r\n",
    "   - **Additional File**: `classes.txt` - A file listing the relevant ChEBI classes.\r\n",
    "\r\n",
    "3. **Processed Data Stage 2**:\r\n",
    "   - **File**: `data.pt`\r\n",
    "   - **Description**: This final stage includes the encoded data in a format compatible with PyTorch, ready for model input. This stage also references data splits when available.\r\n",
    "   - **File Path**: `data/${chebi_version}/${dataset_name}/processed/${reader_name}/data.pt`\r\n",
    "   - **Additional File**: `splits.csv` - Contains saved splits for reproducibility.\r\n",
    "\r\n",
    "### Data Splits\r\n",
    "\r\n",
    "- **Creation**: Data splits are generated dynamically \"on the fly\" during training and evaluation to ensure flexibility and adaptability to different tasks.\r\n",
    "- **Reproducibility**: To maintain consistency across different runs, splits can be reproduced by comparing hashes with a fixed seed value.\r\n",
    "\r\n",
    "### Summary of File Paths\r\n",
    "\r\n",
    "- **Raw Data**: `data/${chebi_version}/${dataset_name}/raw`\r\n",
    "- **Processed Data 1**: `data/${chebi_version}/${dataset_name}/processed`\r\n",
    "- **Processed Data 2**: `data/${chebi_version}/${dataset_name}/processed/${reader_name}`\r\n",
    "\r\n",
    "This structured approach to data management ensures that each stage of data processing is well-organized and documented, from raw data acquisition to the preparation of model-ready inputs. It also facilitates reproducibility and traceability across different experiments.\r\n",
    "that each step is well-documented and reproducible.\r\n",
    "sing, from raw input to model-ready formats.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35c1d2b-9d6b-4c10-828b-b5912752c757",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74adb549-9e02-472d-a535-78a584853b52",
   "metadata": {},
   "source": [
    "# 4. Information Stored in the Files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd490270-59b8-4c1c-8b09-204defddf592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322bc926-69ff-4b93-9e95-5e8b85869c38",
   "metadata": {},
   "source": [
    "\n",
    "## data.pkl\n",
    "\n",
    "The `data.pkl` file, generated during the preprocessing stage, contains the processed ChEBI data in a dataframe format. Below is an example of how this data is structured:\n",
    "\n",
    "\n",
    "\n",
    "### Structure of `data.pkl`\n",
    "`data.pkl` as following structure: \n",
    "- **Column 0**: Contains the ID of each ChEBI data instance.\n",
    "- **Column 1**: Contains the name of each ChEBI data instance.\n",
    "- **Column 2**: Contains the SMILES representation of the chemical.\n",
    "- **Column 3 and onwards**: Contains the labels, starting from column 3.\n",
    "\n",
    "This structure ensures that the data is organized and ready for further processing, such as further encoding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d7d16247-092c-4e8d-96c2-ab23931cf766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the data (rows x columns):  (129184, 1335)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>1722</th>\n",
       "      <th>2468</th>\n",
       "      <th>2571</th>\n",
       "      <th>2580</th>\n",
       "      <th>2634</th>\n",
       "      <th>3098</th>\n",
       "      <th>3992</th>\n",
       "      <th>...</th>\n",
       "      <th>143017</th>\n",
       "      <th>143212</th>\n",
       "      <th>143813</th>\n",
       "      <th>146180</th>\n",
       "      <th>147334</th>\n",
       "      <th>156473</th>\n",
       "      <th>166828</th>\n",
       "      <th>166904</th>\n",
       "      <th>167497</th>\n",
       "      <th>167559</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33429</td>\n",
       "      <td>monoatomic monoanion</td>\n",
       "      <td>[*-]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30151</td>\n",
       "      <td>aluminide(1-)</td>\n",
       "      <td>[Al-]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16042</td>\n",
       "      <td>halide anion</td>\n",
       "      <td>[*-]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17051</td>\n",
       "      <td>fluoride</td>\n",
       "      <td>[F-]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28741</td>\n",
       "      <td>sodium fluoride</td>\n",
       "      <td>[F-].[Na+]</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1335 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                  name      SMILES   1722   2468   2571   2580   2634  \\\n",
       "0  33429  monoatomic monoanion        [*-]  False  False  False  False  False   \n",
       "1  30151         aluminide(1-)       [Al-]  False  False  False  False  False   \n",
       "2  16042          halide anion        [*-]  False  False  False  False  False   \n",
       "3  17051              fluoride        [F-]  False  False  False  False  False   \n",
       "4  28741       sodium fluoride  [F-].[Na+]  False  False  False  False  False   \n",
       "\n",
       "    3098   3992  ...  143017  143212  143813  146180  147334  156473  166828  \\\n",
       "0  False  False  ...   False   False   False   False   False   False   False   \n",
       "1  False  False  ...   False   False   False   False   False   False   False   \n",
       "2  False  False  ...   False   False   False   False   False   False   False   \n",
       "3  False  False  ...   False   False   False   False   False   False   False   \n",
       "4  False  False  ...   False   False   False   False   False   False   False   \n",
       "\n",
       "   166904  167497  167559  \n",
       "0   False   False   False  \n",
       "1   False   False   False  \n",
       "2   False   False   False  \n",
       "3   False   False   False  \n",
       "4   False   False   False  \n",
       "\n",
       "[5 rows x 1335 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkl_df = pd.DataFrame(pd.read_pickle(r\"data/chebi_v200/ChEBI50/processed/data.pkl\"))\n",
    "print(\"Size of the data (rows x columns): \", pkl_df.shape)\n",
    "pkl_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5eb482c-ce5b-4efc-b2ec-85ac7b1a78ee",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab110764-216d-4d52-a9d1-4412c8ac8c9d",
   "metadata": {},
   "source": [
    "# 6. Example Molecule: Different Encodings\n",
    "\n",
    "`chebai` supports various encodings for molecules, such as SMILES and SELFIES. Let's take an example molecule and explore its different encodings.\n",
    "\n",
    "### Explanation:\n",
    "- **SMILES (Simplified Molecular Input Line Entry System)**: A linear notation for representing molecular structures.\n",
    "- **SELFIES (SELF-referencIng Embedded Strings)**: A more robust encoding that can handle a broader range of chemical structures.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b0f7974-f262-429c-b064-4207277e22ad",
   "metadata": {},
   "source": [
    "# 7. Additional Useful Features\n",
    "\n",
    "- **Substructure Search**: `chebai` allows you to perform substructure searches within the ChEBI database.\n",
    "- **Property Filters**: You can filter molecules based on specific properties, such as molecular weight or charge.\n",
    "- **Visualization**: `chebai` provides tools for visualizing molecular structures directly within the notebook.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314801c7-9a1c-4247-9809-497f8481ac90",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "This notebook provided an introduction to the `chebai` package, focusing on how data is structured and utilized. With this knowledge, you can start exploring chemical data more effectively using `chebai`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_chebai)",
   "language": "python",
   "name": "env_chebai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
